% Multi-Agent Systems
@article{guo2024llm_multiagent,
  title={Large Language Model based Multi-Agents: A Survey of Progress and Challenges},
  author={Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
  journal={arXiv preprint arXiv:2402.01680},
  year={2024}
}

@article{yehudai2025survey_llm_agents,
  title={Survey on Evaluation of LLM-based Agents},
  author={Asaf Yehudai and Lilach Eden and Alan Li and Guy Uziel and Yilun Zhao and Roy Bar-Haim and Arman Cohan and Michal Shmueli-Scheuer},
  journal={arXiv preprint arXiv:2503.16416},
  year={2025}
}

@article{yan2025beyond_selftalk,
  title={Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems},
  author={Bingyu Yan and Xiaoming Zhang and Litian Zhang and Lian Zhang and Ziyi Zhou and Dezhuang Miao and Chaozhuo Li},
  journal={arXiv preprint arXiv:2502.14321},
  year={2025}
}

@article{ma2024agentboard,
  title={AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents},
  author={Chang Ma and Junlei Zhang and Zhihao Zhu and Cheng Yang and Yujiu Yang and Yaohui Jin and Zhenzhong Lan and Lingpeng Kong},
  journal={arXiv preprint arXiv:2401.13178},
  year={2024}
}

% Direct Preference Optimization
@article{rafailov2023dpo,
  title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{muldrew2024active_preference,
  title={Active Preference Learning for Large Language Models},
  author={William Muldrew and Peter Hayes and Mingtian Zhang and David Barber},
  journal={arXiv preprint arXiv:2402.08114},
  year={2024}
}

@article{wang2024asft,
  title={ASFT: Aligned Supervised Fine-Tuning through Absolute Likelihood},
  author={Ruoyu Wang and Jiachen Sun and Shaowei Hua and Quan Fang},
  journal={arXiv preprint arXiv:2409.10571},
  year={2024}
}

% Email Generation and Text Evaluation
@article{zhang2019email_subject,
  title={This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation},
  author={Rui Zhang and Joel Tetreault},
  journal={arXiv preprint arXiv:1906.03497},
  year={2019}
}

@article{pauli2024persuasive_language,
  title={Measuring and Benchmarking Large Language Models' Capabilities to Generate Persuasive Language},
  author={Amalie Brogaard Pauli and Isabelle Augenstein and Ira Assent},
  journal={arXiv preprint arXiv:2406.17753},
  year={2024}
}

@article{murakami2023nlg_advertising,
  title={Natural Language Generation for Advertising: A Survey},
  author={Soichiro Murakami and Sho Hoshino and Peinan Zhang},
  journal={arXiv preprint arXiv:2306.12719},
  year={2023}
}

@article{zheng2023click_controllable,
  title={Click: Controllable Text Generation with Sequence Likelihood Contrastive Learning},
  author={Chujie Zheng and Pei Ke and Zheng Zhang and Minlie Huang},
  journal={arXiv preprint arXiv:2306.03350},
  year={2023}
}

% Language Model Evaluation
@article{bohnet2022attributed_qa,
  title={Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models},
  author={Bernd Bohnet and Vinh Q. Tran and Pat Verga and Roee Aharoni and Daniel Andor and Livio Baldini Soares and Massimiliano Ciaramita and Jacob Eisenstein},
  journal={arXiv preprint arXiv:2212.08037},
  year={2022}
}

@article{pimentel2024beyond_metrics,
  title={Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks},
  author={Marco AF Pimentel and Cl{\'e}ment Christophe and Tathagata Raha and Prateek Munjal and Praveen K Kanithi and Shadab Khan},
  journal={arXiv preprint arXiv:2407.21072},
  year={2024}
}

% Reasoning Models
@article{marjanovic2025deepseek_thoughtology,
  title={DeepSeek-R1 Thoughtology: Let's $<$think$>$ about LLM Reasoning},
  author={Sara Vera Marjanovi{\'c} and Arkil Patel and Vaibhav Adlakha and Milad Aghajohari and Parishad BehnamGhader and Mehar Bhatia and Aditi Khandelwal and Austin Kraft},
  journal={arXiv preprint arXiv:2504.07128},
  year={2025}
}

@article{sui2025stop_overthinking,
  title={Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models},
  author={Yang Sui and Yu-Neng Chuang and Guanchu Wang and Jiamu Zhang and Tianyi Zhang and Jiayi Yuan and Hongyi Liu and Andrew Wen},
  journal={arXiv preprint arXiv:2503.16419},
  year={2025}
}

% Hybrid Preference Learning and Synthetic Data
@article{gallego2024configurable_safety,
  title={Configurable Preference Tuning with Rubric-Guided Synthetic Data},
  author={Victor Gallego},
  journal={arXiv preprint arXiv:2506.11702},
  year={2024}
}

@article{poddar2024personalizing_rlhf,
  title={Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning},
  author={Sriyash Poddar and Yanming Wan and Hamish Ivison and Abhishek Gupta and Natasha Jaques},
  journal={arXiv preprint arXiv:2408.10075},
  year={2024}
}

@article{chen2024refined_dpo,
  title={Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs},
  author={Víctor Gallego},
  journal={arXiv preprint arXiv:2402.08005},
  year={2024}
}

@article{liu2024rs_dpo,
  title={RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models},
  author={Saeed Khaki and JinJin Li and Lan Ma and Liu Yang and Prathap Ramachandra},
  journal={arXiv preprint arXiv:2402.10038},
  year={2024}
}

% Meta-Evaluation and Pipeline Assessment
@article{chen2024meta_evaluation,
  title={Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate},
  author={Cheng Chen and Hongxuan Tang and Zhirui Chen and Yichao Wu and Ruochen Zhao and Guoyin Wang and Zhongyu Wei},
  journal={arXiv preprint arXiv:2401.16788},
  year={2024}
}

@article{wang2024dynamic_evaluation,
  title={Dynamic Evaluation of Large Language Models by Meta Probing Agents},
  author={Kaijie Zhu and Jindong Wang and Qinlin Zhao and Ruochen Xu and Xing Xie},
  journal={arXiv preprint arXiv:2402.14865},
  year={2024}
}

@article{xu2024consistency_survey,
  title={Consistency in Language Models: Current Landscape, Challenges, and Future Directions},
  author={Junfan Chen and Richong Zhang and Yanyi Jiang and Yongyi Mao},
  journal={arXiv preprint arXiv:2505.00268},
  year={2024}
}

@article{lin2024meta_rewarding,
  title={Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge},
  author={Tianhao Wu and Weizhe Yuan and Olga Golovneva and Jing Xu and Yuandong Tian and Jiantao Jiao and Jason Weston and Sainbayar Sukhbaatar},
  journal={arXiv preprint arXiv:2407.19594},
  year={2024}
}

@article{zhang2024improve_pipeline,
  title={IMPROVE: Iterative Model Pipeline Refinement and Optimization Leveraging LLM Agents},
  author={Xiangyu Zhang and Wangshu Zhang and Yanfu Zhang and Shizhe Diao and Jing Zhang},
  journal={arXiv preprint arXiv:2502.18530},
  year={2024}
}

% Human-AI Collaboration and Scalability
@article{wang2024human_ai_collaboration,
  title={Evaluating Human-AI Collaboration: A Review and Methodological Framework},
  author={Shichao Wang and Jianlong Zhou and Fang Chen and Kathryn Kasmarik},
  journal={arXiv preprint arXiv:2407.19098},
  year={2024}
}

@article{liu2024human_ai_teaming,
  title={A Survey on Human-AI Teaming with Large Pre-Trained Models},
  author={Linxin Song and Jiale Liu and Jieyu Zhang and Shaokun Zhang and Ao Luo and Shijian Lu and Qingyun Wu and Chi Wang},
  journal={arXiv preprint arXiv:2403.04931},
  year={2024}
}

% Reproducibility and Documentation Standards
@article{chen2024reproducibility_hci,
  title={Risk or Chance? Large Language Models and Reproducibility in Human-Computer Interaction Research},
  author={Jiuang Chen and MohammadHossein Jarrahi},
  journal={arXiv preprint arXiv:2404.15782},
  year={2024}
}

@article{ma2024reproducibility_query,
  title={A Reproducibility and Generalizability Study of Large Language Models for Query Generation},
  author={Moritz Staudinger and Sibo Dong and Ameer Albahem and Dyaa Albakour and Miguel Martinez},
  journal={arXiv preprint arXiv:2411.14914},
  year={2024}
}

@article{yin2024reproducibility_ml,
  title={Reproducibility in Machine Learning-based Research: Overview, Barriers and Drivers},
  author={Harald Kitzmann and Sören Gröttrup and Michael H. Breitner},
  journal={arXiv preprint arXiv:2406.14325},
  year={2024}
}